{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -------------------------------------------------------------------------------------------\n",
    "#  Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "#  Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.\n",
    "#  -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase grounding\n",
    "\n",
    "This notebook demonstrates the multimodal models introduced in our ECCV 2022 paper:\n",
    "\n",
    "> Boecking, B., Usuyama, N., Bannur, S., Castro, D., Schwaighofer, A., Hyland, S., Wetscherek, M., Naumann, T., Nori, A., Alvarez-Valle, J., Poon, H., & Oktay, O. (2022). *Making the Most of Text Semantics to Improve Biomedical Visionâ€“Language Processing* ([preprint](https://arxiv.org/abs/2204.09817))\n",
    "\n",
    "Given a chest X-ray and a text prompt, the joint model grounds the phrase in the image, i.e., highlights the regions of the image that share features similar to the phrase.\n",
    "\n",
    "It can be run on Binder without the need of any coding or local installation:\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/microsoft/hi-ml/HEAD?labpath=hi-ml-multimodal%2Fnotebooks%2Fphrase_grounding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first install the `hi-ml-multimodal` Python package, which will allow us to import the `health_multimodal` Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "repo_branch = \"main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = \"git+https://github.com/microsoft/hi-ml.git\"\n",
    "subdirectory = \"hi-ml-multimodal\"\n",
    "pip_source = f\"{repo_url}@{repo_branch}#subdirectory={subdirectory}\"\n",
    "%pip install --quiet {pip_source}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from health_multimodal.text import get_cxr_bert_inference\n",
    "from health_multimodal.image import get_cxr_resnet_inference\n",
    "from health_multimodal.vlp import ImageTextInferenceEngine\n",
    "from health_multimodal.common.visualization import plot_phrase_grounding_similarity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load multimodal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text and image models from [Hugging Face ðŸ¤—](https://aka.ms/biovil-models) and instantiate the inference engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inference = get_cxr_bert_inference()\n",
    "image_inference = get_cxr_resnet_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the joint inference engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_text_inference = ImageTextInferenceEngine(\n",
    "    image_inference_engine=image_inference,\n",
    "    text_inference_engine=text_inference,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phrase_grounding(image_path: Path, text_prompt: str) -> None:\n",
    "    similarity_map = image_text_inference.get_similarity_map_from_raw_data(\n",
    "        image_path=image_path,\n",
    "        query_text=text_prompt,\n",
    "        interpolation=\"bilinear\",\n",
    "    )\n",
    "    plot_phrase_grounding_similarity_map(\n",
    "        image_path=image_path,\n",
    "        similarity_map=similarity_map,\n",
    "    )\n",
    "\n",
    "def plot_phrase_grounding_from_url(image_url: str, text_prompt: str) -> None:\n",
    "    image_path = Path(tempfile.tempdir, \"downloaded_chest_xray.jpg\")\n",
    "    !curl -s -L -o {image_path} {image_url}\n",
    "    plot_phrase_grounding(image_path, text_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We will run inference on a chest X-ray from [Radiopaedia](https://radiopaedia.org/), but any can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt = \"Pneumonia in the right lung\"\n",
    "image_url = \"https://prod-images-static.radiopaedia.org/images/1371188/0a1f5edc85aa58d5780928cb39b08659c1fc4d6d7c7dce2f8db1d63c7c737234_gallery.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_phrase_grounding_from_url(image_url, text_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('himl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "81d407843c86749c7dcabccff3a65d2b56decd11bb12e42b6d2748d7e4f3c116"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
