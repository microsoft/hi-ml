{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -------------------------------------------------------------------------------------------\n",
    "#  Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "#  Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.\n",
    "#  -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase grounding\n",
    "\n",
    "This notebook demonstrates the usage of the BioViL-T image and text models in a multimodal phrase grounding setting.\n",
    "Given a chest X-ray and a radiology text phrase, the joint model grounds the phrase in the image, i.e., highlights the regions of the image that share features similar to the phrase.\n",
    "Please refer to [our ECCV and CVPR papers](https://hi-ml.readthedocs.io/en/latest/multimodal.html#credit) for further details.\n",
    "\n",
    "The notebook can also be run on Binder without the need of any coding or local installation:\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/microsoft/hi-ml/HEAD?labpath=hi-ml-multimodal%2Fnotebooks%2Fphrase_grounding.ipynb)\n",
    "\n",
    "This demo is solely for research evaluation purposes, not intended to be a medical product or clinical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first install the `hi-ml-multimodal` Python package, which will allow us to import the `health_multimodal` Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "pip_source = \"hi-ml-multimodal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install {pip_source}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from health_multimodal.common.visualization import plot_phrase_grounding_similarity_map\n",
    "from health_multimodal.text import get_bert_inference\n",
    "from health_multimodal.text.utils import BertEncoderType\n",
    "from health_multimodal.image import get_image_inference\n",
    "from health_multimodal.image.utils import ImageModelType\n",
    "from health_multimodal.vlp import ImageTextInferenceEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load multimodal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text and image models from [Hugging Face ðŸ¤—](https://aka.ms/biovil-models) and instantiate the inference engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inference = get_bert_inference(BertEncoderType.BIOVIL_T_BERT)\n",
    "image_inference = get_image_inference(ImageModelType.BIOVIL_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the joint inference engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_text_inference = ImageTextInferenceEngine(\n",
    "    image_inference_engine=image_inference,\n",
    "    text_inference_engine=text_inference,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_text_inference.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeBox = Tuple[float, float, float, float]\n",
    "\n",
    "def plot_phrase_grounding(image_path: Path, text_prompt: str, bboxes: List[TypeBox]) -> None:\n",
    "    similarity_map = image_text_inference.get_similarity_map_from_raw_data(\n",
    "        image_path=image_path,\n",
    "        query_text=text_prompt,\n",
    "        interpolation=\"bilinear\",\n",
    "    )\n",
    "    plot_phrase_grounding_similarity_map(\n",
    "        image_path=image_path,\n",
    "        similarity_map=similarity_map,\n",
    "        bboxes=bboxes\n",
    "    )\n",
    "\n",
    "def plot_phrase_grounding_from_url(image_url: str, text_prompt: str, bboxes: List[TypeBox]) -> None:\n",
    "    image_path = Path(tempfile.tempdir, \"downloaded_chest_xray.jpg\")\n",
    "    !curl -s -L -o {image_path} {image_url}\n",
    "    plot_phrase_grounding(image_path, text_prompt, bboxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We will run inference on a chest X-ray from [Open-i](https://openi.nlm.nih.gov/detailedresult?img=CXR111_IM-0076-1001&req=4), but any other chest X-ray image in DICOM or JPEG format can be used for research purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://openi.nlm.nih.gov/imgs/512/242/1445/CXR1445_IM-0287-4004.png\"\n",
    "text_prompt = \"Left basilar consolidation seen\"\n",
    "# Ground-truth bounding box annotation(s) for the input text prompt\n",
    "bboxes = [\n",
    "    (306, 168, 124, 101),\n",
    "]\n",
    "\n",
    "text = (\n",
    "    'The ground-truth bounding box annotation for the phrase'\n",
    "    f' *{text_prompt}* is shown in the middle figure (in black).'\n",
    ")\n",
    "\n",
    "display(Markdown(text))\n",
    "plot_phrase_grounding_from_url(image_url, text_prompt, bboxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.3 ('multimodal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3ed4ebeb13ecf0e023e91854a12f6980e67b335857d302451652e7fbb2d2298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
